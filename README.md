# Disaster_Response_Pipelines
Udacity's Data Science Nanodegree project. Here an ETL will be build to read the dataset provided, clean the data, and then store it in a SQLite database. Then a machine learning pipeline will be created that uses NLTK, as well as scikit-learn's Pipeline and GridSearchCV to output a final model that uses the message column to predict classifications for 36 categories (multi-output classification). The model will be exported to a pickle file and in the last step, the results will be displayed in a Flask web app
